{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import processing\n",
    "#import ds\n",
    "#import ml\n",
    "#import model_saving\n",
    "#import TS\n",
    "#import TA\n",
    "# Load the necessary packages and modules\n",
    "#from pandas_datareader import data as pdr\n",
    "#import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy\n",
    "import numpy as np\n",
    "import math as m\n",
    "#import talib\n",
    "import pickle\n",
    "#from sklearn import svm\n",
    "\n",
    "#from hmmlearn.hmm import GaussianHMM\n",
    "#from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename='/home/octo/Dropbox'+ '/SPY24.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import a Kalman filter and other useful libraries\n",
    "from pykalman import KalmanFilter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import matplotlib.pyplot as plt\n",
    "from scipy import poly1d\n",
    "\n",
    "def kalman_ma(data):\n",
    "    x=data.Open\n",
    "    # Construct a Kalman filter\n",
    "    kf = KalmanFilter(transition_matrices = [1],\n",
    "                  observation_matrices = [1],\n",
    "                  initial_state_mean = x[1],\n",
    "                  initial_state_covariance = 1,\n",
    "                  observation_covariance=1,\n",
    "                  transition_covariance=.01)\n",
    "\n",
    "    # Use the observed values of the price to get a rolling mean\n",
    "    state_means, _ = kf.filter(x.values)\n",
    "    state_means = pd.Series(state_means.flatten(), index=x.index)\n",
    "    #df_ml['km']=state_means\n",
    "    return state_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading csv file\n",
    "def get_csv_pd(path):\n",
    "    spy_pd=pd.read_csv(filename,sep=',',dtype={'Stock':np.str,'Close':np.float32,'High':np.float32,'Low':np.float32,'askSize':np.float32,'askPrice':np.float32,'Volume':np.float32,\n",
    "                                           'bidPrice':np.float32,'bidSize':np.float32,'lastprice':np.float32},index_col=0,parse_dates=True)\n",
    "    return spy_pd\n",
    "def processing(df):\n",
    "    #df=df.drop(['Stock'], axis=1)\n",
    "    df['Open']=((df.askPrice+df.bidPrice)/2).shift(-1)\n",
    "    df['vwap']=((df.loc[:,'bidPrice']*df.loc[:,'bidSize'])+(df.loc[:,'askPrice']*df.loc[:,'askSize']))/(df.loc[:,'bidSize']+df.loc[:,'askSize'])\n",
    "    df['km']=kalman_ma(df)\n",
    "    df['OC']=(df.Open-df.Close)\n",
    "    df['HO']=(df.High-df.Open)\n",
    "    df['OL']=(df.Open-df.Low)\n",
    "    df['UL']=df.askPrice.rolling(20).max()\n",
    "    df['LL']=df.bidPrice.rolling(20).min()\n",
    "    #df['state']=np.where(np.logical_and(df.km>df.UL,df.bidSize>50),1,\n",
    "    #                 np.where(np.logical_and(df.km<df.LL,df.askSize>50),-1,0))\n",
    "    #df=df.drop(['Volume','High','Low','Close','askPrice','bidPrice','askSize','bidSize','lastprice'], axis=1)\n",
    "    return df\n",
    "def normalize(df):\n",
    "    df.Open=df.Open/df.Open.rolling(20).mean()## target\n",
    "    df.vwap=df.vwap/df.lastprice.rolling(20).mean()\n",
    "    df.OC=df.OC/df.OC.rolling(20).mean()\n",
    "    df.HO=df.HO/df.HO.rolling(20).mean()\n",
    "    df.OL=df.OL/df.OL.rolling(20).mean()\n",
    "    df.UL=df.UL/df.lastprice.rolling(20).mean()\n",
    "    df.LL=df.LL/df.lastprice.rolling(20).mean()\n",
    "    df.km=df.km/df.lastprice.rolling(20).mean() \n",
    "    df.Volume=df.Volume/df.Volume.rolling(20).mean() \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=get_csv_pd(filename)\n",
    "data=processing(data)\n",
    "data=normalize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=data[['Open','vwap','OC','HO','OL','UL','LL','km','Volume']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Open      float64\n",
       "vwap      float64\n",
       "OC        float64\n",
       "HO        float64\n",
       "OL        float64\n",
       "UL        float64\n",
       "LL        float64\n",
       "km        float64\n",
       "Volume    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset=dataset[500:200000]\n",
    "dataset=dataset[2500:35000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>vwap</th>\n",
       "      <th>OC</th>\n",
       "      <th>HO</th>\n",
       "      <th>OL</th>\n",
       "      <th>UL</th>\n",
       "      <th>LL</th>\n",
       "      <th>km</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-04-24 20:50:48.881208</th>\n",
       "      <td>0.999973</td>\n",
       "      <td>0.999970</td>\n",
       "      <td>1.026639</td>\n",
       "      <td>1.004318</td>\n",
       "      <td>0.988228</td>\n",
       "      <td>1.000053</td>\n",
       "      <td>0.999865</td>\n",
       "      <td>0.999972</td>\n",
       "      <td>1.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-24 20:50:48.885337</th>\n",
       "      <td>0.999977</td>\n",
       "      <td>0.999974</td>\n",
       "      <td>1.021951</td>\n",
       "      <td>1.003572</td>\n",
       "      <td>0.990235</td>\n",
       "      <td>1.000056</td>\n",
       "      <td>0.999869</td>\n",
       "      <td>0.999972</td>\n",
       "      <td>1.000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-24 20:50:48.889516</th>\n",
       "      <td>0.999981</td>\n",
       "      <td>0.999977</td>\n",
       "      <td>1.018232</td>\n",
       "      <td>1.002976</td>\n",
       "      <td>0.991847</td>\n",
       "      <td>1.000060</td>\n",
       "      <td>0.999872</td>\n",
       "      <td>0.999973</td>\n",
       "      <td>1.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-24 20:50:48.893596</th>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.999981</td>\n",
       "      <td>1.014539</td>\n",
       "      <td>1.002380</td>\n",
       "      <td>0.993464</td>\n",
       "      <td>1.000064</td>\n",
       "      <td>0.999876</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>1.000019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-24 20:50:48.897602</th>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999956</td>\n",
       "      <td>1.010873</td>\n",
       "      <td>1.001785</td>\n",
       "      <td>0.995086</td>\n",
       "      <td>1.000068</td>\n",
       "      <td>0.999880</td>\n",
       "      <td>0.999976</td>\n",
       "      <td>1.000017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Open      vwap        OC        HO        OL  \\\n",
       "2018-04-24 20:50:48.881208  0.999973  0.999970  1.026639  1.004318  0.988228   \n",
       "2018-04-24 20:50:48.885337  0.999977  0.999974  1.021951  1.003572  0.990235   \n",
       "2018-04-24 20:50:48.889516  0.999981  0.999977  1.018232  1.002976  0.991847   \n",
       "2018-04-24 20:50:48.893596  0.999985  0.999981  1.014539  1.002380  0.993464   \n",
       "2018-04-24 20:50:48.897602  0.999989  0.999956  1.010873  1.001785  0.995086   \n",
       "\n",
       "                                  UL        LL        km    Volume  \n",
       "2018-04-24 20:50:48.881208  1.000053  0.999865  0.999972  1.000011  \n",
       "2018-04-24 20:50:48.885337  1.000056  0.999869  0.999972  1.000009  \n",
       "2018-04-24 20:50:48.889516  1.000060  0.999872  0.999973  1.000008  \n",
       "2018-04-24 20:50:48.893596  1.000064  0.999876  0.999975  1.000019  \n",
       "2018-04-24 20:50:48.897602  1.000068  0.999880  0.999976  1.000017  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Below 1 and <previous == sell along with classification signal+ mean of last two open price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=dataset.dropna()\n",
    "dataset=dataset.values\n",
    "dataset = dataset.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(107)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9999812, 0.9999782, 1.0238303, 1.0030894, 0.9666328, 1.0000507,\n",
       "       0.9999756, 0.9999975, 1.0000194], dtype=float32)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import MinMaxScaler\n",
    "# normalize the dataset\n",
    "#scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "#dataset = scaler.fit_transform(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[i:(i+look_back), 0]\n",
    "        b = dataset[i:(i+look_back), 1]\n",
    "        c = dataset[i:(i+look_back), 2]\n",
    "        d = dataset[i:(i+look_back), 3]\n",
    "        e=  dataset[i:(i+look_back), 4]\n",
    "        f = dataset[i:(i+look_back), 5]\n",
    "        g=  dataset[i:(i+look_back), 6]\n",
    "        h=  dataset[i:(i+look_back), 7]\n",
    "        j=  dataset[i:(i+look_back), 8]\n",
    "        dataX.append(np.c_[b,c,d,e,f,g,h,j])\n",
    "        #dataX.append(b)\n",
    "        #dataX.append(c)\n",
    "        #dataX.append(d)\n",
    "        #dataX.append(e)\n",
    "        #dataX.concatenate((a,bT,cT,dT,eT),axis=1)\n",
    "        dataY.append(dataset[i + look_back,0])\n",
    "        #dataY.append(a)\n",
    "    return np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape into X=t and Y=t+1\n",
    "look_back =4\n",
    "X, Y = create_dataset(dataset,look_back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32494, 4, 8)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32494, 4, 8)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=3\n",
    "batch_size=25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.1.6'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "## First Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and fit the LSTM network\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.add(LSTM(6,input_shape=(X.shape[1],X.shape[2])))\n",
    "#model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "#model.fit(X,Y, epochs, batch_size, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model 2\n",
    "https://faroit.github.io/keras-docs/1.0.1/getting-started/sequential-model-guide/\n",
    "https://keras.io/getting-started/sequential-model-guide/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and fit the LSTM network\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32489, 9, 8)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(LSTM(32, return_sequences=True,input_shape=(X.shape[1],X.shape[2])))  # returns a sequence of vectors of dimension 32\n",
    "model.add(LSTM(32, return_sequences=True))  # returns a sequence of vectors of dimension 32\n",
    "model.add(LSTM(32))  # return a single vector of dimension 32\n",
    "model.add(Dense(1, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      " - 59s - loss: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2f44643d68>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(X,Y, epochs,1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________\n",
      "Layer (type)                            Output Shape                        Param #       \n",
      "==========================================================================================\n",
      "lstm_15 (LSTM)                          (None, 4, 32)                       5248          \n",
      "__________________________________________________________________________________________\n",
      "lstm_16 (LSTM)                          (None, 4, 32)                       8320          \n",
      "__________________________________________________________________________________________\n",
      "lstm_17 (LSTM)                          (None, 32)                          8320          \n",
      "__________________________________________________________________________________________\n",
      "dense_4 (Dense)                         (None, 1)                           33            \n",
      "==========================================================================================\n",
      "Total params: 21,921\n",
      "Trainable params: 21,921\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary(90))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://datascience.stackexchange.com/questions/26366/training-an-rnn-with-examples-of-different-lengths-in-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
