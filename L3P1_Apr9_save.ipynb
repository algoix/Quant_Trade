{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/octo/anaconda2/envs/carnd-term1/lib/python3.5/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n",
      "/home/octo/anaconda2/envs/carnd-term1/lib/python3.5/site-packages/sklearn/base.py:311: UserWarning: Trying to unpickle estimator LinearRegression from version 0.18 when using version 0.19.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/home/octo/anaconda2/envs/carnd-term1/lib/python3.5/site-packages/sklearn/base.py:311: UserWarning: Trying to unpickle estimator SVR from version 0.18 when using version 0.19.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/home/octo/anaconda2/envs/carnd-term1/lib/python3.5/site-packages/sklearn/base.py:311: UserWarning: Trying to unpickle estimator SVC from version 0.18 when using version 0.19.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/home/octo/anaconda2/envs/carnd-term1/lib/python3.5/site-packages/sklearn/base.py:311: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.18 when using version 0.19.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#import processing\n",
    "import ds\n",
    "import ml\n",
    "import model_saving\n",
    "import TS\n",
    "import TA\n",
    "# Load the necessary packages and modules\n",
    "#from pandas_datareader import data as pdr\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy\n",
    "import numpy as np\n",
    "import math as m\n",
    "import talib\n",
    "import pickle\n",
    "from sklearn import svm\n",
    "\n",
    "from hmmlearn.hmm import GaussianHMM\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename_train ='/home/octo/Dropbox'+ '/SPY9Apr.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loading csv file\n",
    "def get_csv_pd(path):\n",
    "    #spy_pd=pd.read_csv('C:\\\\Users\\Michal\\Dropbox\\IB_data\\SPY.csv',sep=' ',names=['askPrice','askSize','bidPrice','bidSize'],index_col=0,parse_dates=True)\n",
    "    #spy_pd=pd.read_csv(path+'\\SPY.csv',sep=',',names=['askPrice','askSize','bidPrice','bidSize'],index_col=0,parse_dates=True)\n",
    "    spy_pd=pd.read_csv(path,sep=',',dtype={'askPrice':np.float32,'askSize':np.float32,\n",
    "                                           'bidPrice':np.float32,'bidSize':np.float32},index_col=0,parse_dates=True)\n",
    "    #spy_pd = pd.read_csv(path, usecols=['askPrice','askSize','bidPrice','bidSize'], engine='python', skipfooter=3)\n",
    "    return spy_pd\n",
    "def BA(df):\n",
    "    df.bidPrice=df.loc[:,'bidPrice'].replace(to_replace=0, method='ffill')\n",
    "    df.bidSize=df.loc[:,'bidSize'].replace(to_replace=0, method='ffill')\n",
    "    df.askPrice=df.loc[:,'askPrice'].replace(to_replace=0, method='ffill')\n",
    "    df.askSize=df.loc[:,'askSize'].replace(to_replace=0, method='ffill')\n",
    "    df=df.dropna()\n",
    "    return df\n",
    "def preprocessing_mar(df):\n",
    "    df=df.dropna()\n",
    "    # to exclude 0\n",
    "    #data=data[data['bidPrice']>240]\n",
    "    #data=data[data['askPrice']>240]\n",
    "    df=df[df['bidPrice']>df.bidPrice.mean()-df.bidPrice.std()]\n",
    "    df=df[df['askPrice']>df.askPrice.mean()-df.askPrice.std()]\n",
    "    df['Open']=(df.askPrice+df.bidPrice)/2\n",
    "    df['Close']=df.Open.shift(1)\n",
    "    df['High']=df.askPrice.rolling(10).max()\n",
    "    df['Low']=df.bidPrice.rolling(10).min()\n",
    "    df['Volume']=df.askSize+df.bidSize\n",
    "    vwap=((df.loc[:,'bidPrice']*df.loc[:,'bidSize'])+(df.loc[:,'askPrice']*df.loc[:,'askSize']))/(df.loc[:,'bidSize']+df.loc[:,'askSize'])\n",
    "    df['spread']=(df.Close-vwap)\n",
    "    #df['Up']=np.where(np.logical_and(df.Close.diff(60)>0.04,df.Close.diff(1)>0.0),1,0)\n",
    "    #df['Dn']=np.where(np.logical_and(df.Close.diff(60)<-0.04,df.Close.diff(1)<0.0),-1,0)\n",
    "    #df['UD']=np.where(np.logical_and(df.Close.diff(60)>0.04,df.Close.diff(1)>0.0),1,\n",
    "    #                 np.where(np.logical_and(df.Close.diff(60)<-0.04,df.Close.diff(1)<0.0),-1,0))\n",
    "    df['UD']=np.where(df.Close.diff(60)>0.06,1,np.where(df.Close.diff(60)<-0.06,-1,0))\n",
    "    #df['sc']=np.where(df.Close.diff(60)>0.04,1,np.where(df.Close.diff(60)<-0.04,-1,0))\n",
    "    df=df.dropna()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data=get_csv_pd(filename_train)\n",
    "data=BA(data)\n",
    "data=preprocessing_mar(data)\n",
    "data_km=ml.kalman_ma(data)\n",
    "data['ckm']=data.Close-data_km\n",
    "data['rsi']=talib.RSI(np.array(data.Close.astype('float64')),timeperiod=10)\n",
    "data['atr']=talib.ATR(np.array(data.High.astype('float64')),np.array(data.Low.astype('float64')),np.array(data.Close.astype('float64')),timeperiod=10)\n",
    "data['mom']=talib.MOM(np.array(data.Close.astype('float64')), timeperiod=10)\n",
    "#data['ret']=np.log(data.Close/data.Close.shift(12))\n",
    "data=data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data=data[38000:45300].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UD\n",
      "-1     5008\n",
      " 0    79509\n",
      " 1     3203\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.groupby('UD').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(data.groupby('sc').size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting to HMM and decoding ..."
     ]
    },
    {
     "data": {
      "text/plain": [
       "GaussianHMM(algorithm='viterbi', covariance_type='full', covars_prior=0.01,\n",
       "      covars_weight=1, init_params='stmc', means_prior=0, means_weight=0,\n",
       "      min_covar=0.001, n_components=5, n_iter=1000, params='stmc',\n",
       "      random_state=None, startprob_prior=1.0, tol=0.01, transmat_prior=1.0,\n",
       "      verbose=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from hmmlearn.hmm import GaussianHMM\n",
    "print(\"fitting to HMM and decoding ...\", end=\"\")\n",
    "# Make an HMM instance and execute fit\n",
    "model_hmm = GaussianHMM(n_components=5, covariance_type=\"full\", n_iter=1000)\n",
    "model_hmm.fit(data[['askPrice', 'askSize', 'bidPrice', 'bidSize','High','Low','spread','ckm','rsi', 'atr','mom']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['markov_hmm.pkl']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(model_hmm, \"markov_hmm.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import recall_score\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X=data[['askPrice', 'askSize', 'bidPrice', 'bidSize','High','Low','spread','ckm','rsi', 'atr','mom']]\n",
    "#X=data[['askPrice', 'askSize', 'bidPrice', 'bidSize','spread','rsi', 'atr','mom']]\n",
    "Y=data.UD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=14, ratio ='minority')\n",
    "X_o,Y_o = sm.fit_sample(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features=9, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=11, n_jobs=1,\n",
       "            oob_score=False, random_state=13, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEED=13\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=11,\n",
    "    max_features=9,\n",
    "    random_state=SEED\n",
    ")\n",
    "\n",
    "rf.fit(X_o,Y_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9271946104728311\n"
     ]
    }
   ],
   "source": [
    "# Kfold validation\n",
    "import pandas\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "kfold = model_selection.KFold(n_splits=20, random_state=SEED)\n",
    "results = model_selection.cross_val_score(rf, X_o,Y_o, cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename_rf = 'rf.sav'\n",
    "pickle.dump(rf, open(filename_rf, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
